{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6bcbc9e-b5be-4e62-a7f5-d81ca3fb3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PAVAN\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\PAVAN\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 13s 13s/step - loss: 64306.2266\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63975.1914\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63974.0391\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63974.0391\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 13s 13s/step - loss: 63974.0391\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 12s 12s/step - loss: 63974.0391\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63974.0391\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 12s 12s/step - loss: 63973.7734\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 13s 13s/step - loss: 63973.7734\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 13s 13s/step - loss: 63973.7734\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 16s 16s/step - loss: 63973.7734\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 14s 14s/step - loss: 63973.7734\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 12s 12s/step - loss: 63973.7734\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 12s 12s/step - loss: 63973.7734\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 12s 12s/step - loss: 63973.7734\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 10s 10s/step - loss: 63973.7734\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 11s 11s/step - loss: 63973.7734\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 12s 12s/step - loss: 63973.7734\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 12s 12s/step - loss: 63973.7734\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 22s 22s/step - loss: 63973.7734\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 16s 16s/step - loss: 63973.7734\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 19s 19s/step - loss: 63973.7734\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 21s 21s/step - loss: 63973.7734\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 21s 21s/step - loss: 63973.7734\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 63973.7734\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 63973.7734\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 63973.7734\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 16s 16s/step - loss: 63973.7734\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 63973.7734\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 20s 20s/step - loss: 63973.7734\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 63973.7734\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 63973.7734\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 63973.7734\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 17s 17s/step - loss: 63973.7734\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 20s 20s/step - loss: 63973.7734\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 19s 19s/step - loss: 63973.7734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2698a6e1150>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "import svgpathtools as svg\n",
    "\n",
    "def svg_to_array(svg_path):\n",
    "    # Read the SVG file\n",
    "    paths, attributes = svg.svg2paths(svg_path)\n",
    "    \n",
    "    # Determine the dimensions of the image\n",
    "    if 'width' in attributes[0] and 'height' in attributes[0]:\n",
    "        width = int(attributes[0]['width'].replace('px', ''))\n",
    "        height = int(attributes[0]['height'].replace('px', ''))\n",
    "    elif 'viewBox' in attributes[0]:\n",
    "        viewBox = attributes[0]['viewBox'].split(' ')\n",
    "        width = int(viewBox[2])\n",
    "        height = int(viewBox[3])\n",
    "    else:\n",
    "        width, height = 512, 512  # Default size if width and height are not specified\n",
    "    \n",
    "    # Create a blank canvas\n",
    "    image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    # Plot the SVG paths onto the canvas\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for path in paths:\n",
    "        for segment in path:\n",
    "            x = [segment.start.real, segment.end.real]\n",
    "            y = [segment.start.imag, segment.end.imag]\n",
    "            ax.plot(x, y, 'k-')  # 'k-' means black lines\n",
    "    \n",
    "    ax.set_xlim(0, width)\n",
    "    ax.set_ylim(height, 0)  # Flip the y-axis to match SVG coordinate system\n",
    "    ax.axis('off')\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    # Convert the plot to a numpy array\n",
    "    image = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Remove alpha channel\n",
    "    image = image[:, :, :3]\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Paths for the input and output SVG images\n",
    "input_svg_path = 'problems/frag0.svg'\n",
    "output_svg_path = 'problems/frag01_sol.svg'\n",
    "\n",
    "# Convert SVG to numpy arrays\n",
    "input_image = svg_to_array(input_svg_path)\n",
    "output_image = svg_to_array(output_svg_path)\n",
    "\n",
    "# Define the encoder\n",
    "def build_encoder(input_layer):\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    \n",
    "    return pool3, conv1, conv2, conv3\n",
    "\n",
    "# Define the decoder\n",
    "def build_decoder(encoded, conv1, conv2, conv3):\n",
    "    up3 = UpSampling2D((2, 2))(encoded)\n",
    "    concat3 = concatenate([up3, conv3])\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat3)\n",
    "    \n",
    "    up2 = UpSampling2D((2, 2))(conv4)\n",
    "    concat2 = concatenate([up2, conv2])\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat2)\n",
    "    \n",
    "    up1 = UpSampling2D((2, 2))(conv5)\n",
    "    concat1 = concatenate([up1, conv1])\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat1)\n",
    "    \n",
    "    output_layer = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(conv6)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "# Build the model\n",
    "def build_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    encoded, conv1, conv2, conv3 = build_encoder(input_layer)\n",
    "    output_layer = build_decoder(encoded, conv1, conv2, conv3)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Define input shape based on loaded images\n",
    "input_shape = input_image.shape\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "X_train = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
    "Y_train = np.expand_dims(output_image, axis=0)  # Add batch dimension\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=1)  # Training with a batch size of 1 since we have only one pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c321d2bb-a88c-49d4-bea0-250bffc4735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Function to test the model\n",
    "def test_model(svg_path, model):\n",
    "    # Preprocess the SVG image\n",
    "    test_image = svg_to_array(svg_path)\n",
    "    test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predicted_image = model.predict(test_image)\n",
    "    \n",
    "    # Post-process the output\n",
    "    predicted_image = np.squeeze(predicted_image)  # Remove batch dimension\n",
    "    predicted_image = (predicted_image * 255).astype(np.uint8)  # Rescale to 0-255 and convert to uint8\n",
    "    \n",
    "    return predicted_image\n",
    "\n",
    "# Test the model with a new SVG image\n",
    "test_svg_path = 'problems/frag1.svg'  # Path to your test SVG file\n",
    "predicted_output = test_model(test_svg_path, model)\n",
    "\n",
    "# Visualize the output\n",
    "plt.imshow(predicted_output)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f544325-2f10-493d-b8bd-af64c7a1f26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a9783-f65f-4999-b741-b2aeeb2d23f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 480, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 480, 640, 64)         1792      ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooli  (None, 240, 320, 64)         0         ['conv2d_22[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 240, 320, 128)        73856     ['max_pooling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooli  (None, 120, 160, 128)        0         ['conv2d_23[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 120, 160, 256)        295168    ['max_pooling2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooli  (None, 60, 80, 256)          0         ['conv2d_24[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampli  (None, 120, 160, 256)        0         ['max_pooling2d_14[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 120, 160, 512)        0         ['up_sampling2d_10[0][0]',    \n",
      " e)                                                                  'conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 120, 160, 256)        1179904   ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampli  (None, 240, 320, 256)        0         ['conv2d_25[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenat  (None, 240, 320, 384)        0         ['up_sampling2d_11[0][0]',    \n",
      " e)                                                                  'conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 240, 320, 128)        442496    ['concatenate_11[0][0]']      \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampli  (None, 480, 640, 128)        0         ['conv2d_26[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 480, 640, 192)        0         ['up_sampling2d_12[0][0]',    \n",
      " e)                                                                  'conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 480, 640, 64)         110656    ['concatenate_12[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 480, 640, 3)          1731      ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2105603 (8.03 MB)\n",
      "Trainable params: 2105603 (8.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "X_train shape: (5, 480, 640, 3)\n",
      "Y_train shape: (5, 480, 640, 3)\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 60s 12s/step - loss: 64447.3867\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 72s 16s/step - loss: 64016.4570\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 88s 15s/step - loss: 64016.1016\n",
      "Epoch 4/50\n",
      "1/2 [==============>...............] - ETA: 1:03 - loss: 64026.6797"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "import svgpathtools as svg\n",
    "import os\n",
    "\n",
    "def svg_to_array(svg_path):\n",
    "    # Read the SVG file\n",
    "    paths, attributes = svg.svg2paths(svg_path)\n",
    "    \n",
    "    # Determine the dimensions of the image\n",
    "    if 'width' in attributes[0] and 'height' in attributes[0]:\n",
    "        width = int(attributes[0]['width'].replace('px', ''))\n",
    "        height = int(attributes[0]['height'].replace('px', ''))\n",
    "    elif 'viewBox' in attributes[0]:\n",
    "        viewBox = attributes[0]['viewBox'].split(' ')\n",
    "        width = int(viewBox[2])\n",
    "        height = int(viewBox[3])\n",
    "    else:\n",
    "        width, height = 512, 512  # Default size if width and height are not specified\n",
    "    \n",
    "    # Create a blank canvas\n",
    "    image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    # Plot the SVG paths onto the canvas\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for path in paths:\n",
    "        for segment in path:\n",
    "            x = [segment.start.real, segment.end.real]\n",
    "            y = [segment.start.imag, segment.end.imag]\n",
    "            ax.plot(x, y, 'k-')  # 'k-' means black lines\n",
    "    \n",
    "    ax.set_xlim(0, width)\n",
    "    ax.set_ylim(height, 0)  # Flip the y-axis to match SVG coordinate system\n",
    "    ax.axis('off')\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    # Convert the plot to a numpy array\n",
    "    image = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Remove alpha channel\n",
    "    image = image[:, :, :3]\n",
    "    \n",
    "    return image\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        if filename.endswith('.svg'):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = svg_to_array(image_path)\n",
    "            images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "def build_encoder(input_layer):\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    \n",
    "    return pool3, conv1, conv2, conv3\n",
    "\n",
    "def build_decoder(encoded, conv1, conv2, conv3):\n",
    "    up3 = UpSampling2D((2, 2))(encoded)\n",
    "    concat3 = concatenate([up3, conv3])\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat3)\n",
    "    \n",
    "    up2 = UpSampling2D((2, 2))(conv4)\n",
    "    concat2 = concatenate([up2, conv2])\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat2)\n",
    "    \n",
    "    up1 = UpSampling2D((2, 2))(conv5)\n",
    "    concat1 = concatenate([up1, conv1])\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat1)\n",
    "    \n",
    "    output_layer = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(conv6)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "def build_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    encoded, conv1, conv2, conv3 = build_encoder(input_layer)\n",
    "    output_layer = build_decoder(encoded, conv1, conv2, conv3)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Load multiple input and output images\n",
    "input_images = load_images_from_directory('input_svg')\n",
    "output_images = load_images_from_directory('output_svg')\n",
    "\n",
    "# Define input shape based on loaded images\n",
    "input_shape = input_images.shape[1:]  # (height, width, channels)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Check shapes of the training data\n",
    "print(f'X_train shape: {input_images.shape}')\n",
    "print(f'Y_train shape: {output_images.shape}')\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_images, output_images, epochs=50, batch_size=4)  # Adjust batch_size if needed\n",
    "\n",
    "def test_model(svg_path, model):\n",
    "    # Preprocess the SVG image\n",
    "    test_image = svg_to_array(svg_path)\n",
    "    test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predicted_image = model.predict(test_image)\n",
    "    \n",
    "    # Post-process the output\n",
    "    predicted_image = np.squeeze(predicted_image)  # Remove batch dimension\n",
    "    predicted_image = (predicted_image * 255).astype(np.uint8)  # Rescale to 0-255 and convert to uint8\n",
    "    \n",
    "    return predicted_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4511696f-b09a-4b27-a01c-f179c86cbcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image shape: (1, 480, 640, 3)\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Test the model with a new SVG image\n",
    "test_svg_path = 'problems/frag0.svg'  # Path to your test SVG file\n",
    "predicted_output = test_model(test_svg_path, model)\n",
    "\n",
    "# Debug: Visualize the test image and the predicted output\n",
    "test_image = svg_to_array(test_svg_path)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image)\n",
    "plt.title('Test Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predicted_output)\n",
    "plt.title('Predicted Output')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b95623-47f5-47ff-9062-ba15ee1d0e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
